{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f515d4fb-c376-4109-8581-2ec5454c534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Enable async in Jupyter\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pytz\n",
    "import holidays\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import logging # Import logging module\n",
    "\n",
    "# Memory threshold (e.g., 90% of available memory)\n",
    "MEMORY_THRESHOLD = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9605f6-8658-41fd-9c2f-a0ab87858115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 2\n",
    "# --- Logging Configuration ---\n",
    "# Custom formatter to use HKT time\n",
    "class HKTFormatter(logging.Formatter):\n",
    "    def formatTime(self, record, datefmt=None):\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "        dt = datetime.fromtimestamp(record.created, tz=pytz.UTC).astimezone(hkt_tz)\n",
    "        return dt.strftime(datefmt or '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Clear existing handlers to prevent duplication\n",
    "logger = logging.getLogger('NewsMonitor')\n",
    "logger.handlers = []\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler = logging.FileHandler('monitor.log', encoding='utf-8')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = HKTFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Discord Message Logger\n",
    "discord_logger = logging.getLogger('DiscordLogger')\n",
    "discord_logger.handlers = []\n",
    "discord_logger.setLevel(logging.INFO)\n",
    "discord_file_handler = logging.FileHandler('discord_messages.log', encoding='utf-8')\n",
    "discord_file_handler.setLevel(logging.INFO)\n",
    "discord_formatter = HKTFormatter('%(asctime)s - News ID: %(news_id)s - Message: %(discord_message)s')\n",
    "discord_file_handler.setFormatter(discord_formatter)\n",
    "discord_logger.addHandler(discord_file_handler)\n",
    "\n",
    "# Health Check Logger\n",
    "health_check_logger = logging.getLogger('HealthCheckLogger')\n",
    "health_check_logger.handlers = []\n",
    "health_check_logger.setLevel(logging.INFO)\n",
    "health_check_file_handler = logging.FileHandler('health_check.log', encoding='utf-8')\n",
    "health_check_file_handler.setLevel(logging.INFO)\n",
    "health_check_formatter = HKTFormatter('%(asctime)s - %(message)s')\n",
    "health_check_file_handler.setFormatter(health_check_formatter)\n",
    "health_check_logger.addHandler(health_check_file_handler)\n",
    "# --- End Logging Configuration ---\n",
    "\n",
    "# Configuration\n",
    "FINNHUB_API_KEY = \"cumn7d1r01qsapi0gk1gcumn7d1r01qsapi0gk20\"\n",
    "DISCORD_WEBHOOK = \"https://discord.com/api/webhooks/1383694378014347375/vF5a3E5ePvHUCnJMk9zCdoApKdHsTbFBLzZ8ZaQPE6w7UhGodl44lF1o-YUhCa2B0WOv\"\n",
    "DISCORD_ALERTS = True\n",
    "NEWS_STORAGE_DIR = \"news_data\"\n",
    "METADATA_FILE = os.path.join(NEWS_STORAGE_DIR, \"latest_news_timestamps.json\")\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"TSLA\", \"NVDA\", \"JPM\", \"JNJ\", \"V\", \"PG\",\n",
    "    \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\", \"NFLX\", \"ADBE\", \"CRM\", \"KO\", \"PEP\",\n",
    "    \"TMO\", \"ABT\", \"AVGO\", \"CSCO\", \"CMCSA\", \"XOM\", \"WMT\", \"VZ\", \"MRK\", \"PFE\",\n",
    "    \"INTC\", \"T\", \"ABBV\", \"ORCL\", \"CVX\", \"ACN\", \"DHR\", \"MCD\", \"NKE\", \"PM\"\n",
    "]\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "os.makedirs(NEWS_STORAGE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83bce37-1806-410c-ab3d-413abe53a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3 \n",
    "class NewsFetcher:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    async def fetch_single_ticker_news(self, ticker, session):\n",
    "        request_time = datetime.now(pytz.UTC).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "        current_date = datetime.now(pytz.UTC)\n",
    "        current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "        url = f\"https://finnhub.io/api/v1/company-news?symbol={ticker}&from={current_date_str}&to={current_date_str}&token={self.api_key}\"\n",
    "        logger.debug(f\"Fetching news for {ticker} with URL: {url}\")\n",
    "        \n",
    "        backoff = [2, 4, 8]\n",
    "        for retry in range(3):\n",
    "            try:\n",
    "                async with session.get(url) as response:\n",
    "                    response_time = datetime.now(pytz.UTC).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "                    if response.status == 429:\n",
    "                        delay = backoff[retry]\n",
    "                        logger.warning(f\"Rate limit hit for {ticker}. Retrying in {delay}s... (Attempt {retry+1})\")\n",
    "                        await asyncio.sleep(delay)\n",
    "                        continue\n",
    "                    if response.status == 200:\n",
    "                        news = await response.json()\n",
    "                        logger.info(f\"[API] Fetched {len(news)} items for {ticker} - Request: {request_time}, Response: {response_time}\")\n",
    "                        processed_news = []\n",
    "                        for item in news:\n",
    "                            if 'datetime' in item and isinstance(item['datetime'], (int, float)) and 'id' in item:\n",
    "                                item_date = datetime.fromtimestamp(item['datetime'], tz=pytz.UTC)\n",
    "                                if item_date.date() != current_date.date():\n",
    "                                    logger.warning(f\"[Warning] Skipping news item for {ticker} with out-of-range date {item_date.strftime('%Y-%m-%d')}: {item.get('headline', 'N/A')}\")\n",
    "                                    continue\n",
    "                                item['ticker'] = ticker\n",
    "                                item['summary'] = item.get('summary', '')\n",
    "                                processed_news.append(item)\n",
    "                            else:\n",
    "                                logger.warning(f\"[Warning] Skipping news item for {ticker} due to missing/invalid 'datetime' or 'id': {item.get('headline', 'N/A')}\")\n",
    "                        if not news:\n",
    "                            logger.info(f\"[Info] No news returned for {ticker} at {response_time}\")\n",
    "                        if len(news) != len(processed_news):\n",
    "                            logger.debug(f\"[Debug] Filtered {len(news) - len(processed_news)} items for {ticker} due to date or data issues\")\n",
    "                        return processed_news\n",
    "                    else:\n",
    "                        logger.error(f\"[Error] HTTP {response.status} for {ticker} at {response_time}. (Attempt {retry+1})\")\n",
    "                        return []\n",
    "            except aiohttp.ClientError as e:\n",
    "                logger.error(f\"[Error] Network error for {ticker} (retry {retry+1}): {e}\")\n",
    "                await asyncio.sleep(backoff[retry])\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Error] Unexpected error for {ticker} (retry {retry+1}): {e}\")\n",
    "                await asyncio.sleep(backoff[retry])\n",
    "        logger.error(f\"[Error] Failed to fetch news for {ticker} after 3 retries.\")\n",
    "        return []\n",
    "\n",
    "    async def fetch_batch(self, tickers, session):\n",
    "        all_news = []\n",
    "        for ticker in tickers:\n",
    "            result = await self.fetch_single_ticker_news(ticker, session)\n",
    "            if isinstance(result, list):\n",
    "                all_news.extend(result)\n",
    "            else:\n",
    "                logger.error(f\"[Error] Failed to fetch news for {ticker}: {result}\")\n",
    "            await asyncio.sleep(0.2)  # Small delay between requests to prevent bursting\n",
    "        return all_news\n",
    "\n",
    "\n",
    "class NewsProcessor:\n",
    "    def __init__(self, storage_dir, discord_webhook, discord_enabled):\n",
    "        self.storage_dir = storage_dir\n",
    "        self.discord_webhook = discord_webhook\n",
    "        self.discord_enabled = discord_enabled\n",
    "        self.latest_ticker_timestamps = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        metadata_file = os.path.join(self.storage_dir, \"latest_news_timestamps.json\")\n",
    "        if os.path.exists(metadata_file):\n",
    "            try:\n",
    "                with open(metadata_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"[Warning] Error loading metadata: {e}. Starting with empty metadata.\")\n",
    "        return {}\n",
    "\n",
    "    def _save_metadata(self):\n",
    "        metadata_file = os.path.join(self.storage_dir, \"latest_news_timestamps.json\")\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(metadata_file), exist_ok=True)\n",
    "            with open(metadata_file, 'w') as f:\n",
    "                json.dump(self.latest_ticker_timestamps, f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Error] Error saving metadata: {e}\")\n",
    "\n",
    "    def _get_news_filepath(self, item):\n",
    "        if 'datetime' not in item or not isinstance(item['datetime'], (int, float)):\n",
    "            logger.warning(f\"Warning: 'datetime' missing/invalid in item for path generation: {item.get('id', 'N/A')}\")\n",
    "            timestamp = datetime.now(pytz.UTC)\n",
    "        else:\n",
    "            try:\n",
    "                timestamp = datetime.fromtimestamp(item['datetime'], tz=pytz.UTC)\n",
    "            except (ValueError, TypeError) as e:\n",
    "                logger.error(f\"[Error] Invalid timestamp for news item {item.get('id', 'N/A')}: {e}\")\n",
    "                timestamp = datetime.now(pytz.UTC)\n",
    "        date_str = timestamp.strftime('%Y-%m-%d')\n",
    "        ticker_dir = os.path.join(self.storage_dir, date_str, item['ticker'])\n",
    "        os.makedirs(ticker_dir, exist_ok=True)\n",
    "        filename = f\"{item['id']}.json\"\n",
    "        return os.path.join(ticker_dir, filename)\n",
    "\n",
    "    def _news_exists(self, item):\n",
    "        filepath = self._get_news_filepath(item)\n",
    "        return os.path.exists(filepath)\n",
    "\n",
    "    async def _send_discord(self, message, news_id=\"N/A\"):\n",
    "        if not self.discord_enabled:\n",
    "            return\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    async with session.post(self.discord_webhook, json={\"content\": message, \"username\": \"News Monitor\"}) as response:\n",
    "                        if response.status == 200:\n",
    "                            logger.info(f\"Discord message sent for News ID: {news_id}\")\n",
    "                            discord_logger.info(\"\", extra={\"news_id\": news_id, \"discord_message\": message})\n",
    "                            return\n",
    "                        elif response.status == 429:\n",
    "                            retry_after = (await response.json()).get('retry_after', 1) / 1000\n",
    "                            logger.warning(f\"[Warning] Rate limited sending Discord message for News ID {news_id}. Retrying after {retry_after}s.\")\n",
    "                            await asyncio.sleep(retry_after)\n",
    "                        else:\n",
    "                            logger.error(f\"[Error] Discord error sending message for News ID {news_id}: HTTP {response.status}\")\n",
    "                            return\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"[Error] Discord error sending message for News ID {news_id}: {e}\")\n",
    "                    await asyncio.sleep(2 ** attempt)\n",
    "\n",
    "    async def process_batch(self, news_items, session):\n",
    "        new_items_count = 0\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "        send_time = datetime.now(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "        for item in news_items:\n",
    "            if not self._news_exists(item):\n",
    "                try:\n",
    "                    filepath = self._get_news_filepath(item)\n",
    "                    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(item, f, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    self.latest_ticker_timestamps[item['ticker']] = item['datetime']\n",
    "                    \n",
    "                    hkt_time = datetime.fromtimestamp(item['datetime'], tz=pytz.UTC).astimezone(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "                    url_line = f\"**URL**: {item['url']}\\n\" if item.get('url') else \"\"\n",
    "                    message = (\n",
    "                        \"##############\\n\"\n",
    "                        f\"**Title**: {item['headline']}\\n\"\n",
    "                        f\"**Ticker**: {item['ticker']}\\n\"\n",
    "                        f\"**Time**: {hkt_time}\\n\"\n",
    "                        f\"**News ID**: {item['id']}\\n\"\n",
    "                        f\"{url_line}\"\n",
    "                        f\"**Summary**: ||{item['summary']}||\\n\"\n",
    "                        f\"**Source**: {item.get('source', 'Unknown')}\\n\"\n",
    "                        \"##############\"\n",
    "                    )\n",
    "                    await self._send_discord(message, news_id=item['id'])\n",
    "                    logger.info(f\"[Sent] Sent to Discord for {item['ticker']} at {send_time}\")\n",
    "                    new_items_count += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"[Error] Error saving news item {item.get('id', 'N/A')}: {e}\")\n",
    "        self._save_metadata()\n",
    "        return new_items_count\n",
    "\n",
    "\n",
    "class HealthChecker:\n",
    "    def __init__(self, fetcher, processor, tickers):\n",
    "        self.fetcher = fetcher\n",
    "        self.processor = processor\n",
    "        self.tickers = tickers\n",
    "        self.pinned_message_id = 1384904190563975339\n",
    "        self.channel_id = \"1383694378014347375\"\n",
    "        self.incidents = []\n",
    "\n",
    "    async def log_health_check(self, message):\n",
    "        try:\n",
    "            health_check_logger.info(message)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Error] Failed to log to HealthCheckLogger: {e}\")\n",
    "            self.incidents.append(f\"Failed to log to health_check.log: {str(e)}\")\n",
    "\n",
    "    async def _edit_pinned_message(self, message_content, news_id=\"N/A\"):\n",
    "        if not self.processor.discord_enabled:\n",
    "            return\n",
    "        try:\n",
    "            edit_url = f\"https://discord.com/api/v10/channels/{self.channel_id}/messages/{self.pinned_message_id}\"\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                for attempt in range(3):\n",
    "                    async with session.patch(\n",
    "                        edit_url,\n",
    "                        headers={\"Authorization\": f\"Bot {self.processor.discord_webhook.split('/')[-1]}\"},\n",
    "                        json={\"content\": message_content}\n",
    "                    ) as response:\n",
    "                        if response.status == 200:\n",
    "                            logger.info(f\"Edited pinned message {self.pinned_message_id} for News ID: {news_id}\")\n",
    "                            discord_logger.info(\"\", extra={\"news_id\": news_id, \"discord_message\": message_content})\n",
    "                            return\n",
    "                        elif response.status == 429:\n",
    "                            retry_after = (await response.json()).get('retry_after', 1) / 1000\n",
    "                            logger.warning(f\"[Warning] Rate limited editing pinned message {self.pinned_message_id}. Retrying after {retry_after}s.\")\n",
    "                            self.incidents.append(f\"Rate limited editing pinned message: HTTP 429\")\n",
    "                            await asyncio.sleep(retry_after)\n",
    "                        else:\n",
    "                            error = f\"Failed to edit pinned message {self.pinned_message_id}: HTTP {response.status}\"\n",
    "                            logger.error(f\"[Error] {error}\")\n",
    "                            self.incidents.append(error)\n",
    "                            return\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Error] Failed to edit pinned message {self.pinned_message_id} for News ID: {news_id}: {e}\")\n",
    "            self.incidents.append(f\"Failed to edit pinned message: {str(e)}\")\n",
    "\n",
    "    async def check_missing_news(self, session, is_market_open):\n",
    "        self.incidents = []\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "        now_hkt = datetime.now(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "        if not is_market_open:\n",
    "            logger.info(\"Market is closed, skipping missing news check.\")\n",
    "            await self.log_health_check(f\"Market is closed, no missing news check performed at {now_hkt}.\")\n",
    "            return\n",
    "        \n",
    "        if not self.processor.latest_ticker_timestamps:\n",
    "            message = f\"[Warning] News database appears empty (no metadata found) at {now_hkt}! Check API or storage.\"\n",
    "            await self.processor._send_discord(message, news_id=\"N/A\")\n",
    "            await self.log_health_check(f\"News database metadata is empty at {now_hkt}.\")\n",
    "            self.incidents.append(\"News database metadata is empty.\")\n",
    "            logger.warning(\"News database metadata is empty.\")\n",
    "            return\n",
    "\n",
    "        max_timestamp = max(self.processor.latest_ticker_timestamps.values())\n",
    "        if (datetime.now(pytz.UTC) - datetime.fromtimestamp(max_timestamp, tz=pytz.UTC)).total_seconds() > 24 * 3600:\n",
    "            message = f\"[Warning] News database not updated in >24h at {now_hkt}! This might indicate a general issue.\"\n",
    "            await self.processor._send_discord(message, news_id=\"N/A\")\n",
    "            await self.log_health_check(f\"News database not updated in >24h at {now_hkt}.\")\n",
    "            self.incidents.append(\"News database not updated in >24h.\")\n",
    "            logger.warning(\"Overall news database not updated in >24h.\")\n",
    "        \n",
    "        missing_news_alerts = []\n",
    "        for ticker in self.tickers[:5]:  # Reduced to 5 tickers\n",
    "            latest_time = self.processor.latest_ticker_timestamps.get(ticker, 0)\n",
    "            if latest_time == 0:\n",
    "                continue\n",
    "            latest_dt = datetime.fromtimestamp(latest_time, tz=pytz.UTC).astimezone(hkt_tz)\n",
    "            if (datetime.now(hkt_tz) - latest_dt).total_seconds() > 6 * 3600:\n",
    "                missing_news_alerts.append(f\"- **{ticker}**: Latest news is >6h old ({latest_dt.strftime('%Y-%m-%d %H:%M HKT')})\")\n",
    "                logger.warning(f\"[Warning] Missing news for {ticker}: Latest news is >6h old.\")\n",
    "\n",
    "        if missing_news_alerts:\n",
    "            alert_message = (\n",
    "                f\"[Alert] **MISSING NEWS ALERT** at {now_hkt}\\n\\n\"\n",
    "                \"The following tickers have not had news updates for a significant period:\\n\"\n",
    "                + \"\\n\".join(missing_news_alerts) +\n",
    "                \"\\n\\n*Unless it is Saturday, Sunday, or a holiday, otherwise we have a problem of reaching no news for a long while.*\"\n",
    "                \"\\n*Please manually pin this message for visibility.*\"\n",
    "            )\n",
    "            await self.processor._send_discord(alert_message, news_id=\"MissingNews\")\n",
    "            await self.log_health_check(f\"Aggregated missing news alert sent to Discord at {now_hkt}.\")\n",
    "            self.incidents.append(\"Missing news detected for some tickers.\")\n",
    "            logger.info(\"Aggregated missing news alert sent to Discord.\")\n",
    "        else:\n",
    "            logger.info(\"No missing news detected for any ticker.\")\n",
    "            await self.log_health_check(f\"No missing news detected for any ticker at {now_hkt}.\")\n",
    "\n",
    "    async def health_check(self, session):\n",
    "        self.incidents = []\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "        now_hkt = datetime.now(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "        sample_tickers = self.tickers[:3]  # Reduced to 3 tickers\n",
    "        raw_news = []\n",
    "        logger.info(f\"Starting health check news fetching for {len(sample_tickers)} tickers at {now_hkt}...\")\n",
    "        try:\n",
    "            news_for_batch = await self.fetcher.fetch_batch(sample_tickers, session)\n",
    "            raw_news.extend(news_for_batch)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Error] Failed to fetch news for health check: {e}\")\n",
    "            self.incidents.append(f\"Failed to fetch news for health check: {str(e)}\")\n",
    "        logger.info(f\"Finished fetching news for health check. Total items fetched: {len(raw_news)}\")\n",
    "\n",
    "        if not raw_news:\n",
    "            logger.info(f\"[Info] Health check: No news returned for test tickers at {now_hkt}.\")\n",
    "            await self.log_health_check(f\"No news returned for test tickers at {now_hkt}\")\n",
    "            health_message = (\n",
    "                f\"[Info] **Health Check** at {now_hkt}\\n\"\n",
    "                f\"Status: Healthy\\n\"\n",
    "                f\"Details: No news returned for test tickers. This is expected if no new news exists.\\n\"\n",
    "                f\"Incidents: {', '.join(self.incidents) if self.incidents else 'None'}\"\n",
    "            )\n",
    "            await self._edit_pinned_message(health_message, news_id=\"HealthCheckInfo\")\n",
    "            return True\n",
    "        \n",
    "        match_count = 0\n",
    "        for item in raw_news:\n",
    "            try:\n",
    "                if self.processor._news_exists(item):\n",
    "                    match_count += 1\n",
    "                else:\n",
    "                    self.incidents.append(f\"News item not found on disk: {item['id']}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Error] Error checking news item {item.get('id', 'N/A')} during health check: {e}\")\n",
    "                self.incidents.append(f\"Error checking news item {item.get('id', 'N/A')}: {str(e)}\")\n",
    "\n",
    "        match_percentage = (match_count / len(raw_news)) * 100 if raw_news else 100\n",
    "        \n",
    "        if match_percentage >= 98:\n",
    "            logger.info(f\"[Success] Health check: {match_percentage:.2f}% match. System is healthy at {now_hkt}.\")\n",
    "            await self.log_health_check(f\"Health check: {match_percentage:.2f}% match. System is healthy at {now_hkt}.\")\n",
    "            health_message = (\n",
    "                f\"[Success] **Health Check** at {now_hkt}\\n\"\n",
    "                f\"Status: Healthy\\n\"\n",
    "                f\"Details: {match_percentage:.2f}% of fetched news items match stored data.\\n\"\n",
    "                f\"Incidents: {', '.join(self.incidents) if self.incidents else 'None'}\"\n",
    "            )\n",
    "            await self._edit_pinned_message(health_message, news_id=\"HealthCheckSuccess\")\n",
    "            return True\n",
    "        elif match_percentage >= 90:\n",
    "            missing_news_in_check = [item for item in raw_news if not self.processor._news_exists(item)]\n",
    "            for item in missing_news_in_check:\n",
    "                hkt_time = datetime.fromtimestamp(item['datetime'], tz=pytz.UTC).astimezone(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "                message = (\n",
    "                    \"##############\\n\"\n",
    "                    f\"**Title**: {item['headline']}\\n\"\n",
    "                    f\"**Ticker**: {item['ticker']}\\n\"\n",
    "                    f\"**Time**: {hkt_time}\\n\"\n",
    "                    f\"**News ID**: {item['id']}\\n\"\n",
    "                    f\"**URL**: {item['url']}\\n\" if item.get('url') else \"\"\n",
    "                    f\"**Summary**: ||{item['summary']}||\\n\"\n",
    "                    f\"**Source**: {item.get('source', 'Unknown')}\\n\"\n",
    "                    \"##############\"\n",
    "                )\n",
    "                await self.processor._send_discord(message, news_id=item['id'])\n",
    "            await self.processor._send_discord(f\"[Warning] News leakage detected at ({match_percentage:.2f}% match) at {now_hkt}.\", news_id=\"HealthCheckWarning\")\n",
    "            await self.log_health_check(f\"News leakage detected at {match_percentage:.2f}% match at {now_hkt}.\")\n",
    "            health_message = (\n",
    "                f\"[Warning] **Health Check** at {now_hkt}\\n\"\n",
    "                f\"Status: Warning\\n\"\n",
    "                f\"Details: {match_percentage:.2f}% match. Some news items not found on disk.\\n\"\n",
    "                f\"Incidents: {', '.join(self.incidents) if self.incidents else 'None'}\"\n",
    "            )\n",
    "            await self._edit_pinned_message(health_message, news_id=\"HealthCheckWarning\")\n",
    "            logger.warning(f\"[Warning] Health check warning: News leakage detected at ({match_percentage:.2f}% match) at {now_hkt}.\")\n",
    "            return False\n",
    "        else:\n",
    "            await self.processor._send_discord(f\"[Error] Significant news leakage detected (<90% match, {match_percentage:.2f}%) at {now_hkt}.\", news_id=\"HealthCheckError\")\n",
    "            await self.log_health_check(f\"Significant news leakage detected at {match_percentage:.2f}% match at {now_hkt}.\")\n",
    "            health_message = (\n",
    "                f\"[Error] **Health Check** at {now_hkt}\\n\"\n",
    "                f\"Status: Failed\\n\"\n",
    "                f\"Details: {match_percentage:.2f}% match. Significant data integrity issue detected.\\n\"\n",
    "                f\"Incidents: {', '.join(self.incidents) if self.incidents else 'None'}\"\n",
    "            )\n",
    "            await self._edit_pinned_message(health_message, news_id=\"HealthCheckError\")\n",
    "            logger.error(f\"[Error] Health check error: Significant news leakage detected at (<90% match, {match_percentage:.2f}%) at {now_hkt}.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "class Scheduler:\n",
    "    def __init__(self, tickers, batch_size, fetcher, processor, health_checker):\n",
    "        self.tickers = tickers\n",
    "        self.batch_size = batch_size\n",
    "        self.fetcher = fetcher\n",
    "        self.processor = processor\n",
    "        self.health_checker = health_checker\n",
    "        self.last_daily_clear_date = None\n",
    "        self.last_health_check = datetime.min.replace(tzinfo=pytz.UTC)\n",
    "\n",
    "    def _is_market_open(self):\n",
    "        us_tz = pytz.timezone('US/Eastern')\n",
    "        now = datetime.now(us_tz)\n",
    "        us_holidays = holidays.US(years=now.year)\n",
    "        return now.weekday() <= 4 and 9.25 <= now.hour + now.minute/60 < 16 and now.date() not in us_holidays\n",
    "\n",
    "    def _is_friday_6pm(self):\n",
    "        us_tz = pytz.timezone('US/Eastern')\n",
    "        now = datetime.now(us_tz)\n",
    "        return now.weekday() == 4 and now.hour == 18 and now.minute == 0\n",
    "\n",
    "    def _is_health_check_time(self, now_hkt, is_market_open):\n",
    "        minute = now_hkt.minute\n",
    "        if is_market_open:\n",
    "            return minute in (0, 30)  # Run at 00 and 30 minutes during market hours\n",
    "        return minute == 0\n",
    "\n",
    "    async def clear_storage(self, now_et):\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "        now_hkt = datetime.now(hkt_tz).strftime('%Y-%m-%d %H:%M HKT')\n",
    "        logger.info(f\"[Clear] Clearing news data and metadata for {now_hkt}...\")\n",
    "        try:\n",
    "            if os.path.exists(self.processor.storage_dir):\n",
    "                shutil.rmtree(self.processor.storage_dir)\n",
    "                logger.info(f\"Removed directory: {self.processor.storage_dir}\")\n",
    "            os.makedirs(self.processor.storage_dir, exist_ok=True)\n",
    "            self.processor.latest_ticker_timestamps = {}\n",
    "            self.processor._save_metadata()\n",
    "            await self.processor._send_discord(f\"[Info] News data directory and metadata cleared at {now_hkt} for deduplication reset.\", news_id=\"ClearStorage\")\n",
    "            logger.info(\"Clear completed.\")\n",
    "            self.last_daily_clear_date = now_et.date()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Error] Failed to clear storage: {e}\")\n",
    "            self.health_checker.incidents.append(f\"Clear storage error: {str(e)}\")\n",
    "\n",
    "    async def run(self):\n",
    "        logger.info(\"Starting news monitoring system...\")\n",
    "        us_tz = pytz.timezone('US/Eastern')\n",
    "        hkt_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                now_utc = datetime.now(pytz.UTC)\n",
    "                now_et = now_utc.astimezone(us_tz)\n",
    "                now_hkt = now_utc.astimezone(hkt_tz)\n",
    "                \n",
    "                if self._is_friday_6pm():\n",
    "                    await self.clear_storage(now_et)\n",
    "                    await asyncio.sleep(60)\n",
    "                    continue\n",
    "\n",
    "                if not self._is_market_open() and now_et.hour >= 16 and (self.last_daily_clear_date is None or self.last_daily_clear_date != now_et.date()):\n",
    "                    await self.clear_storage(now_et)\n",
    "                    await asyncio.sleep(60)\n",
    "                    continue\n",
    "\n",
    "                is_market_open = self._is_market_open()\n",
    "                cycle_time_target = 10  # 4 batches Ã— 2.5 seconds = 10 seconds\n",
    "\n",
    "                start_time = datetime.now(pytz.UTC)\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    total_new = 0\n",
    "                    for i in range(0, len(self.tickers), self.batch_size):\n",
    "                        batch = self.tickers[i:i + self.batch_size]\n",
    "                        batch_start = datetime.now(pytz.UTC)\n",
    "                        logger.debug(f\"Starting batch {i//self.batch_size + 1} for tickers {batch} at {batch_start.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "                        try:\n",
    "                            news_items = await self.fetcher.fetch_batch(batch, session)\n",
    "                            total_new += await self.processor.process_batch(news_items, session)\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"[Error] Failed to process batch {batch}: {e}\")\n",
    "                            self.health_checker.incidents.append(f\"Batch processing error: {str(e)}\")\n",
    "                        batch_elapsed = (datetime.now(pytz.UTC) - batch_start).total_seconds()\n",
    "                        sleep_time = max(2.5 - batch_elapsed, 0)  # Ensure 2.5 seconds per batch\n",
    "                        if sleep_time > 0:\n",
    "                            logger.debug(f\"Sleeping {sleep_time:.2f} seconds after batch {i//self.batch_size + 1}\")\n",
    "                            await asyncio.sleep(sleep_time)\n",
    "                    logger.info(f\"Processed batch cycle. Total new items: {total_new}\")\n",
    "\n",
    "                    if is_market_open and self._is_health_check_time(now_hkt, is_market_open):\n",
    "                        now_hkt_str = now_hkt.strftime('%Y-%m-%d %H:%M HKT')\n",
    "                        logger.info(f\"Running missing news check at {now_hkt_str}...\")\n",
    "                        try:\n",
    "                            await self.health_checker.check_missing_news(session, is_market_open)\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"[Error] Failed to check missing news: {e}\")\n",
    "                            self.health_checker.incidents.append(f\"Missing news check error: {str(e)}\")\n",
    "\n",
    "                        logger.info(f\"Running health check at {now_hkt_str}...\")\n",
    "                        await self.health_checker.log_health_check(f\"Starting health check at {now_hkt_str}\")\n",
    "                        try:\n",
    "                            if not await self.health_checker.health_check(session):\n",
    "                                await self.processor._send_discord(f\"[Alert] Health check failed at {now_hkt_str}! Review logs for details.\", news_id=\"HealthCheckFailure\")\n",
    "                                await self.health_checker.log_health_check(f\"Health check failed at {now_hkt_str}.\")\n",
    "                                logger.error(f\"Health check failed at {now_hkt_str}, pausing for 60 seconds.\")\n",
    "                                await asyncio.sleep(60)\n",
    "                                continue\n",
    "                        except Exception as e:\n",
    "                            await self.health_checker.log_health_check(f\"Health check error at {now_hkt_str}: {str(e)}\")\n",
    "                            logger.error(f\"[Error] Health check error at {now_hkt_str}: {e}\")\n",
    "                            self.health_checker.incidents.append(f\"Health check error: {str(e)}\")\n",
    "                        self.last_health_check = now_utc\n",
    "                        logger.info(f\"Health check completed at {now_hkt_str}.\")\n",
    "\n",
    "                elapsed_time = (datetime.now(pytz.UTC) - start_time).total_seconds()\n",
    "                sleep_time = max(cycle_time_target - elapsed_time, 0)\n",
    "                if is_market_open and sleep_time < 2.5:\n",
    "                    sleep_time = 2.5  # Ensure at least 2.5 seconds before next cycle\n",
    "                if sleep_time > 0:\n",
    "                    logger.info(f\"Sleeping for {sleep_time:.2f} seconds after cycle\")\n",
    "                    await asyncio.sleep(sleep_time)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Critical] Scheduler loop crashed: {e}\")\n",
    "                self.health_checker.incidents.append(f\"Scheduler loop crash: {str(e)}\")\n",
    "                await self.processor._send_discord(f\"[Critical] Scheduler crashed at {now_hkt.strftime('%Y-%m-%d %H:%M HKT')}! Error: {str(e)}\", news_id=\"SchedulerCrash\")\n",
    "                await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437b0b40-5811-49bd-97cb-dd0a7efeeb36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m scheduler\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(main())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(task)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writers, [], timeout)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\selectors.py:305\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 305\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    fetcher = NewsFetcher(FINNHUB_API_KEY)\n",
    "    processor = NewsProcessor(NEWS_STORAGE_DIR, DISCORD_WEBHOOK, DISCORD_ALERTS)\n",
    "    health_checker = HealthChecker(fetcher, processor, TICKERS)\n",
    "    scheduler = Scheduler(TICKERS, BATCH_SIZE, fetcher, processor, health_checker)\n",
    "    logger.info(f\"[Chart] Monitoring {len(TICKERS)} stocks (batch size: {BATCH_SIZE})\")\n",
    "    await scheduler.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dacfa-69fc-4736-aa72-3c960c7f3524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc883b-7f94-479a-abb5-bec4f98e9d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
